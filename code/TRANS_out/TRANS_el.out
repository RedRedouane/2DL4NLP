2021-10-04 14:10:29,804 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-10-04 14:10:29,869 - INFO - joeynmt.data - Loading training data...
2021-10-04 14:10:29,986 - INFO - joeynmt.data - Building vocabulary...
2021-10-04 14:10:30,467 - INFO - joeynmt.data - Loading dev data...
2021-10-04 14:10:30,481 - INFO - joeynmt.data - Loading test data...
2021-10-04 14:10:30,492 - INFO - joeynmt.data - Data loaded.
2021-10-04 14:10:30,493 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-10-04 14:10:31,394 - INFO - joeynmt.model - Enc-dec model built.
2021-10-04 14:10:31,407 - INFO - joeynmt.training - Total params: 33711104
2021-10-04 14:10:35,652 - INFO - joeynmt.helpers - cfg.name                           : TRANS_el
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.src                       : el
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.trg                       : en_s
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.train                     : ../2DL4NLP/all_data/el.en_s/train.bpe
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.dev                       : ../2DL4NLP/all_data/el.en_s/val.bpe
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.test                      : ../2DL4NLP/all_data/el.en_s/test.bpe
2021-10-04 14:10:35,653 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 50
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.src_voc_min_freq          : 0
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.src_voc_limit             : 10000
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.trg_voc_min_freq          : 0
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.trg_voc_limit             : 10000
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : ../2DL4NLP/all_data/el.en_s/el.en_s.vocab.txt
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : ../2DL4NLP/all_data/el.en_s/el.en_s.vocab.txt
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.batch_size            : 80
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-10-04 14:10:35,654 - INFO - joeynmt.helpers - cfg.training.patience              : 1
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.epochs                : 100
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 1000
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/TRANS_el
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 60
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.keep_best_ckpts       : 1
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.training.save_latest_ckpt      : True
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-10-04 14:10:35,655 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4
2021-10-04 14:10:35,656 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - Data set sizes: 
	train 5008,
	valid 551,
	test 602
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - First training example:
	[SRC] el
	[TRG] en
--- Logging error ---
Traceback (most recent call last):
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/logging/__init__.py", line 1036, in emit
    stream.write(msg)
UnicodeEncodeError: 'latin-1' codec can't encode characters in position 141-142: ordinal not in range(256)
Call stack:
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 48, in <module>
    main()
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 35, in main
    train(cfg_file=args.config_path, skip_test=args.skip_test)
  File "/home/lcur0008/joeynmt/joeynmt/training.py", line 835, in train
    trg_vocab=trg_vocab)
  File "/home/lcur0008/joeynmt/joeynmt/helpers.py", line 164, in log_data_info
    " ".join('(%d) %s' % (i, t) for i, t in enumerate(src_vocab.itos[:10])))
Message: 'First 10 words (src): %s'
Arguments: ('(0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) \u03bd\u03b1 (9) of',)
2021-10-04 14:10:35,657 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) \u03bd\u03b1 (9) of
--- Logging error ---
Traceback (most recent call last):
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/logging/__init__.py", line 1036, in emit
    stream.write(msg)
UnicodeEncodeError: 'latin-1' codec can't encode characters in position 141-142: ordinal not in range(256)
Call stack:
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 48, in <module>
    main()
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 35, in main
    train(cfg_file=args.config_path, skip_test=args.skip_test)
  File "/home/lcur0008/joeynmt/joeynmt/training.py", line 835, in train
    trg_vocab=trg_vocab)
  File "/home/lcur0008/joeynmt/joeynmt/helpers.py", line 167, in log_data_info
    " ".join('(%d) %s' % (i, t) for i, t in enumerate(trg_vocab.itos[:10])))
Message: 'First 10 words (trg): %s'
Arguments: ('(0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) \u03bd\u03b1 (9) of',)
2021-10-04 14:10:35,660 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) \u03bd\u03b1 (9) of
2021-10-04 14:10:35,660 - INFO - joeynmt.helpers - Number of Src words (types): 4230
2021-10-04 14:10:35,660 - INFO - joeynmt.helpers - Number of Trg words (types): 4230
2021-10-04 14:10:35,660 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=4),
	decoder=TransformerDecoder(num_layers=6, num_heads=4),
	src_embed=Embeddings(embedding_dim=512, vocab_size=4230),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=4230))
2021-10-04 14:10:35,670 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 80
	total batch size (w. parallel & accumulation): 80
2021-10-04 14:10:35,670 - INFO - joeynmt.training - EPOCH 1
2021-10-04 14:10:47,405 - INFO - joeynmt.training - Epoch   1: total training loss 8716.46
2021-10-04 14:10:47,405 - INFO - joeynmt.training - EPOCH 2
2021-10-04 14:10:59,054 - INFO - joeynmt.training - Epoch   2: total training loss 7958.95
2021-10-04 14:10:59,054 - INFO - joeynmt.training - EPOCH 3
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 8223185 ON r30n2 CANCELLED AT 2021-10-04T14:11:09 ***
slurmstepd: error: *** STEP 8223185.0 ON r30n2 CANCELLED AT 2021-10-04T14:11:09 ***
