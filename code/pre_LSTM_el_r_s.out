2021-10-03 21:29:03,162 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-10-03 21:29:03,231 - INFO - joeynmt.data - Loading training data...
2021-10-03 21:29:03,335 - INFO - joeynmt.data - Building vocabulary...
2021-10-03 21:29:03,785 - INFO - joeynmt.data - Loading dev data...
2021-10-03 21:29:03,798 - INFO - joeynmt.data - Loading test data...
2021-10-03 21:29:03,808 - INFO - joeynmt.data - Data loaded.
2021-10-03 21:29:03,809 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-10-03 21:29:04,348 - INFO - joeynmt.model - Enc-dec model built.
2021-10-03 21:29:04,354 - INFO - joeynmt.training - Total params: 24738816
2021-10-03 21:29:09,098 - INFO - joeynmt.training - Loading model from ../checkpoints/LSTM_el_r.ckpt
2021-10-03 21:29:09,467 - INFO - joeynmt.training - Reset tracking of the best checkpoint.
2021-10-03 21:29:09,468 - INFO - joeynmt.training - Reset train data iterator.
2021-10-03 21:29:09,485 - INFO - joeynmt.helpers - cfg.name                           : pre_LSTM_el_r_s
2021-10-03 21:29:09,485 - INFO - joeynmt.helpers - cfg.data.src                       : tr_s
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.trg                       : en_s
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.train                     : ../2DL4NLP/all_data/tr_s.en_s/train.bpe
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.dev                       : ../2DL4NLP/all_data/tr_s.en_s/val.bpe
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.test                      : ../2DL4NLP/all_data/tr_s.en_s/test.bpe
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 50
2021-10-03 21:29:09,486 - INFO - joeynmt.helpers - cfg.data.src_voc_min_freq          : 0
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.data.src_voc_limit             : 100000
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.data.trg_voc_min_freq          : 0
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.data.trg_voc_limit             : 100000
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : ../2DL4NLP/all_data/tr_s.en_s/tr_s.en_s.vocab.txt
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : ../2DL4NLP/all_data/tr_s.en_s/tr_s.en_s.vocab.txt
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-10-03 21:29:09,487 - INFO - joeynmt.helpers - cfg.training.load_model            : ../checkpoints/LSTM_el_r.ckpt
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.reset_best_ckpt       : True
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.reset_iter_state      : True
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 5e-07
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-10-03 21:29:09,488 - INFO - joeynmt.helpers - cfg.training.clip_grad_norm        : 1.0
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.batch_size            : 80
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.patience              : 10
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.5
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.epochs                : 20
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 100
2021-10-03 21:29:09,489 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 1000
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/pre_LSTM_el_r_s
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2021-10-03 21:29:09,490 - INFO - joeynmt.helpers - cfg.training.keep_best_ckpts       : 1
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.training.save_latest_ckpt      : True
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.rnn_type         : lstm
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : False
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.bidirectional    : False
2021-10-03 21:29:09,491 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.2
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 1
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.rnn_type         : lstm
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : False
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.emb_scale        : False
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 1024
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.2
2021-10-03 21:29:09,492 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_dropout   : 0.2
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 1
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - cfg.model.decoder.input_feeding    : True
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - cfg.model.decoder.init_hidden      : bridge
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - cfg.model.decoder.attention        : bahdanau
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - Data set sizes: 
	train 5177,
	valid 551,
	test 602
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - First training example:
	[SRC] tr
	[TRG] en
2021-10-03 21:29:09,493 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) a (9) &quot;
2021-10-03 21:29:09,494 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) ." (7) the (8) a (9) &quot;
2021-10-03 21:29:09,494 - INFO - joeynmt.helpers - Number of Src words (types): 4136
2021-10-03 21:29:09,494 - INFO - joeynmt.helpers - Number of Trg words (types): 4136
2021-10-03 21:29:09,494 - INFO - joeynmt.training - Model(
	encoder=RecurrentEncoder(LSTM(512, 512, batch_first=True)),
	decoder=RecurrentDecoder(rnn=LSTM(1536, 1024, batch_first=True), attention=BahdanauAttention),
	src_embed=Embeddings(embedding_dim=512, vocab_size=4136),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=4136))
2021-10-03 21:29:09,505 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 80
	total batch size (w. parallel & accumulation): 80
2021-10-03 21:29:09,505 - INFO - joeynmt.training - EPOCH 1
Traceback (most recent call last):
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 48, in <module>
    main()
  File "/home/lcur0008/joeynmt/joeynmt/__main__.py", line 35, in main
    train(cfg_file=args.config_path, skip_test=args.skip_test)
  File "/home/lcur0008/joeynmt/joeynmt/training.py", line 846, in train
    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)
  File "/home/lcur0008/joeynmt/joeynmt/training.py", line 460, in train_and_validate
    self.optimizer.step()
  File "/home/lcur0008/.local/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/lcur0008/.local/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/lcur0008/.local/lib/python3.7/site-packages/torch/optim/adam.py", line 118, in step
    eps=group['eps'])
  File "/home/lcur0008/.local/lib/python3.7/site-packages/torch/optim/_functional.py", line 86, in adam
    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
RuntimeError: The size of tensor a (4104) must match the size of tensor b (4136) at non-singleton dimension 0
srun: error: r30n1: task 0: Exited with exit code 1
