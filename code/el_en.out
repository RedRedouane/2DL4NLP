2021-09-30 18:59:44,329 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-09-30 18:59:44,441 - INFO - joeynmt.data - Loading training data...
2021-09-30 18:59:44,534 - INFO - joeynmt.data - Building vocabulary...
2021-09-30 18:59:46,866 - INFO - joeynmt.data - Loading dev data...
2021-09-30 18:59:46,879 - INFO - joeynmt.data - Loading test data...
2021-09-30 18:59:46,891 - INFO - joeynmt.data - Data loaded.
2021-09-30 18:59:46,891 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-09-30 18:59:48,033 - INFO - joeynmt.model - Enc-dec model built.
2021-09-30 18:59:48,040 - INFO - joeynmt.training - Total params: 51313120
2021-09-30 18:59:52,528 - INFO - joeynmt.helpers - cfg.name                           : el_en_model
2021-09-30 18:59:52,528 - INFO - joeynmt.helpers - cfg.data.src                       : el
2021-09-30 18:59:52,528 - INFO - joeynmt.helpers - cfg.data.trg                       : en
2021-09-30 18:59:52,528 - INFO - joeynmt.helpers - cfg.data.train                     : ../2DL4NLP/all_data/train
2021-09-30 18:59:52,528 - INFO - joeynmt.helpers - cfg.data.dev                       : ../2DL4NLP/all_data/val
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.test                      : ../2DL4NLP/all_data/test
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 50
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.src_voc_min_freq          : 0
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.src_voc_limit             : 10000
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.trg_voc_min_freq          : 0
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.data.trg_voc_limit             : 10000
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.optimizer             : sgd
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.5
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 5e-07
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-09-30 18:59:52,529 - INFO - joeynmt.helpers - cfg.training.clip_grad_norm        : 5.0
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.batch_size            : 80
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.patience              : 1
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.9
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.epochs                : 100
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 7362
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 1000
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/BIG_model
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 60
2021-09-30 18:59:52,530 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.rnn_type         : lstm
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 620
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : False
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 1000
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.bidirectional    : True
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.2
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 1
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.rnn_type         : lstm
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 620
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : False
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.emb_scale        : False
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 1000
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.2
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_dropout   : 0.2
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 1
2021-09-30 18:59:52,531 - INFO - joeynmt.helpers - cfg.model.decoder.input_feeding    : True
2021-09-30 18:59:52,532 - INFO - joeynmt.helpers - cfg.model.decoder.init_hidden      : bridge
2021-09-30 18:59:52,532 - INFO - joeynmt.helpers - cfg.model.decoder.attention        : bahdanau
2021-09-30 18:59:52,532 - INFO - joeynmt.helpers - Data set sizes: 
	train 5551,
	valid 551,
	test 602
2021-09-30 18:59:52,532 - INFO - joeynmt.helpers - First training example:
	[SRC] el
	[TRG] en
--- Logging error ---
Traceback (most recent call last):
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/logging/__init__.py", line 1036, in emit
    stream.write(msg)
UnicodeEncodeError: 'latin-1' codec can't encode characters in position 126-127: ordinal not in range(256)
Call stack:
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lcur0006/joeynmt/joeynmt/__main__.py", line 48, in <module>
    main()
  File "/home/lcur0006/joeynmt/joeynmt/__main__.py", line 35, in main
    train(cfg_file=args.config_path, skip_test=args.skip_test)
  File "/home/lcur0006/joeynmt/joeynmt/training.py", line 835, in train
    trg_vocab=trg_vocab)
  File "/home/lcur0006/joeynmt/joeynmt/helpers.py", line 164, in log_data_info
    " ".join('(%d) %s' % (i, t) for i, t in enumerate(src_vocab.itos[:10])))
Message: 'First 10 words (src): %s'
Arguments: ('(0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) \u03bd\u03b1 (7) ." (8) \u03c4\u03bf (9) \u03ba\u03b1\u03b9',)
2021-09-30 18:59:52,532 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) \u03bd\u03b1 (7) ." (8) \u03c4\u03bf (9) \u03ba\u03b1\u03b9
2021-09-30 18:59:52,534 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) the (6) . (7) ." (8) of (9) to
2021-09-30 18:59:52,534 - INFO - joeynmt.helpers - Number of Src words (types): 10004
2021-09-30 18:59:52,535 - INFO - joeynmt.helpers - Number of Trg words (types): 8422
2021-09-30 18:59:52,535 - INFO - joeynmt.training - Model(
	encoder=RecurrentEncoder(LSTM(620, 1000, batch_first=True, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(1620, 1000, batch_first=True), attention=BahdanauAttention),
	src_embed=Embeddings(embedding_dim=620, vocab_size=10004),
	trg_embed=Embeddings(embedding_dim=620, vocab_size=8422))
2021-09-30 18:59:52,562 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 80
	total batch size (w. parallel & accumulation): 80
2021-09-30 18:59:52,563 - INFO - joeynmt.training - EPOCH 1
2021-09-30 19:00:12,603 - INFO - joeynmt.training - Epoch   1: total training loss 11214.42
2021-09-30 19:00:12,604 - INFO - joeynmt.training - EPOCH 2
2021-09-30 19:00:32,380 - INFO - joeynmt.training - Epoch   2: total training loss 9916.18
2021-09-30 19:00:32,380 - INFO - joeynmt.training - EPOCH 3
2021-09-30 19:00:52,119 - INFO - joeynmt.training - Epoch   3: total training loss 9117.55
2021-09-30 19:00:52,120 - INFO - joeynmt.training - EPOCH 4
2021-09-30 19:01:11,781 - INFO - joeynmt.training - Epoch   4: total training loss 9453.96
2021-09-30 19:01:11,782 - INFO - joeynmt.training - EPOCH 5
2021-09-30 19:01:31,661 - INFO - joeynmt.training - Epoch   5: total training loss 8612.19
2021-09-30 19:01:31,662 - INFO - joeynmt.training - EPOCH 6
2021-09-30 19:01:51,354 - INFO - joeynmt.training - Epoch   6: total training loss 8297.64
2021-09-30 19:01:51,355 - INFO - joeynmt.training - EPOCH 7
2021-09-30 19:02:11,196 - INFO - joeynmt.training - Epoch   7: total training loss 7967.46
2021-09-30 19:02:11,197 - INFO - joeynmt.training - EPOCH 8
2021-09-30 19:02:30,938 - INFO - joeynmt.training - Epoch   8: total training loss 7650.62
2021-09-30 19:02:30,939 - INFO - joeynmt.training - EPOCH 9
2021-09-30 19:02:50,644 - INFO - joeynmt.training - Epoch   9: total training loss 7380.47
2021-09-30 19:02:50,644 - INFO - joeynmt.training - EPOCH 10
2021-09-30 19:03:10,300 - INFO - joeynmt.training - Epoch  10: total training loss 7090.47
2021-09-30 19:03:10,301 - INFO - joeynmt.training - EPOCH 11
2021-09-30 19:03:30,162 - INFO - joeynmt.training - Epoch  11: total training loss 6818.28
2021-09-30 19:03:30,163 - INFO - joeynmt.training - EPOCH 12
2021-09-30 19:03:50,003 - INFO - joeynmt.training - Epoch  12: total training loss 6612.75
2021-09-30 19:03:50,004 - INFO - joeynmt.training - EPOCH 13
2021-09-30 19:04:09,878 - INFO - joeynmt.training - Epoch  13: total training loss 6441.91
2021-09-30 19:04:09,878 - INFO - joeynmt.training - EPOCH 14
2021-09-30 19:04:29,513 - INFO - joeynmt.training - Epoch  14: total training loss 6272.30
2021-09-30 19:04:29,514 - INFO - joeynmt.training - EPOCH 15
2021-09-30 19:04:35,186 - INFO - joeynmt.training - Epoch  15, Step:     1000, Batch Loss:    79.584908, Tokens per Sec:     5047, Lr: 0.500000
2021-09-30 19:04:49,231 - INFO - joeynmt.training - Epoch  15: total training loss 6092.04
2021-09-30 19:04:49,231 - INFO - joeynmt.training - EPOCH 16
2021-09-30 19:05:08,947 - INFO - joeynmt.training - Epoch  16: total training loss 5908.52
2021-09-30 19:05:08,947 - INFO - joeynmt.training - EPOCH 17
2021-09-30 19:05:28,504 - INFO - joeynmt.training - Epoch  17: total training loss 5733.30
2021-09-30 19:05:28,504 - INFO - joeynmt.training - EPOCH 18
2021-09-30 19:05:48,095 - INFO - joeynmt.training - Epoch  18: total training loss 5541.32
2021-09-30 19:05:48,095 - INFO - joeynmt.training - EPOCH 19
2021-09-30 19:06:07,721 - INFO - joeynmt.training - Epoch  19: total training loss 5332.64
2021-09-30 19:06:07,722 - INFO - joeynmt.training - EPOCH 20
2021-09-30 19:06:27,584 - INFO - joeynmt.training - Epoch  20: total training loss 5128.69
2021-09-30 19:06:27,585 - INFO - joeynmt.training - EPOCH 21
2021-09-30 19:06:47,264 - INFO - joeynmt.training - Epoch  21: total training loss 4930.44
2021-09-30 19:06:47,264 - INFO - joeynmt.training - EPOCH 22
2021-09-30 19:07:07,184 - INFO - joeynmt.training - Epoch  22: total training loss 4729.08
2021-09-30 19:07:07,185 - INFO - joeynmt.training - EPOCH 23
2021-09-30 19:07:26,969 - INFO - joeynmt.training - Epoch  23: total training loss 4515.84
2021-09-30 19:07:26,969 - INFO - joeynmt.training - EPOCH 24
2021-09-30 19:07:46,610 - INFO - joeynmt.training - Epoch  24: total training loss 4301.81
2021-09-30 19:07:46,610 - INFO - joeynmt.training - EPOCH 25
2021-09-30 19:08:06,228 - INFO - joeynmt.training - Epoch  25: total training loss 4082.73
2021-09-30 19:08:06,229 - INFO - joeynmt.training - EPOCH 26
2021-09-30 19:08:25,920 - INFO - joeynmt.training - Epoch  26: total training loss 3865.51
2021-09-30 19:08:25,921 - INFO - joeynmt.training - EPOCH 27
2021-09-30 19:08:45,321 - INFO - joeynmt.training - Epoch  27: total training loss 3651.36
2021-09-30 19:08:45,321 - INFO - joeynmt.training - EPOCH 28
2021-09-30 19:09:05,120 - INFO - joeynmt.training - Epoch  28: total training loss 3438.60
2021-09-30 19:09:05,121 - INFO - joeynmt.training - EPOCH 29
2021-09-30 19:09:16,566 - INFO - joeynmt.training - Epoch  29, Step:     2000, Batch Loss:    45.442944, Tokens per Sec:     5082, Lr: 0.500000
2021-09-30 19:09:24,734 - INFO - joeynmt.training - Epoch  29: total training loss 3234.29
2021-09-30 19:09:24,734 - INFO - joeynmt.training - EPOCH 30
2021-09-30 19:09:44,477 - INFO - joeynmt.training - Epoch  30: total training loss 3012.26
2021-09-30 19:09:44,477 - INFO - joeynmt.training - EPOCH 31
2021-09-30 19:10:04,068 - INFO - joeynmt.training - Epoch  31: total training loss 2841.05
2021-09-30 19:10:04,068 - INFO - joeynmt.training - EPOCH 32
2021-09-30 19:10:23,925 - INFO - joeynmt.training - Epoch  32: total training loss 2653.64
2021-09-30 19:10:23,925 - INFO - joeynmt.training - EPOCH 33
2021-09-30 19:10:43,650 - INFO - joeynmt.training - Epoch  33: total training loss 2465.19
2021-09-30 19:10:43,650 - INFO - joeynmt.training - EPOCH 34
2021-09-30 19:11:03,585 - INFO - joeynmt.training - Epoch  34: total training loss 2287.11
2021-09-30 19:11:03,585 - INFO - joeynmt.training - EPOCH 35
2021-09-30 19:11:23,516 - INFO - joeynmt.training - Epoch  35: total training loss 2119.30
2021-09-30 19:11:23,516 - INFO - joeynmt.training - EPOCH 36
2021-09-30 19:11:43,355 - INFO - joeynmt.training - Epoch  36: total training loss 1952.40
2021-09-30 19:11:43,356 - INFO - joeynmt.training - EPOCH 37
2021-09-30 19:12:03,011 - INFO - joeynmt.training - Epoch  37: total training loss 1798.86
2021-09-30 19:12:03,011 - INFO - joeynmt.training - EPOCH 38
2021-09-30 19:12:22,715 - INFO - joeynmt.training - Epoch  38: total training loss 1671.74
2021-09-30 19:12:22,715 - INFO - joeynmt.training - EPOCH 39
2021-09-30 19:12:42,218 - INFO - joeynmt.training - Epoch  39: total training loss 1534.67
2021-09-30 19:12:42,218 - INFO - joeynmt.training - EPOCH 40
2021-09-30 19:13:01,940 - INFO - joeynmt.training - Epoch  40: total training loss 1419.23
2021-09-30 19:13:01,940 - INFO - joeynmt.training - EPOCH 41
2021-09-30 19:13:21,717 - INFO - joeynmt.training - Epoch  41: total training loss 1292.89
2021-09-30 19:13:21,717 - INFO - joeynmt.training - EPOCH 42
2021-09-30 19:13:41,463 - INFO - joeynmt.training - Epoch  42: total training loss 1197.88
2021-09-30 19:13:41,463 - INFO - joeynmt.training - EPOCH 43
2021-09-30 19:13:58,572 - INFO - joeynmt.training - Epoch  43, Step:     3000, Batch Loss:    14.661735, Tokens per Sec:     5082, Lr: 0.500000
2021-09-30 19:14:01,157 - INFO - joeynmt.training - Epoch  43: total training loss 1102.57
2021-09-30 19:14:01,157 - INFO - joeynmt.training - EPOCH 44
2021-09-30 19:14:20,836 - INFO - joeynmt.training - Epoch  44: total training loss 1029.56
2021-09-30 19:14:20,836 - INFO - joeynmt.training - EPOCH 45
2021-09-30 19:14:40,611 - INFO - joeynmt.training - Epoch  45: total training loss 937.72
2021-09-30 19:14:40,611 - INFO - joeynmt.training - EPOCH 46
2021-09-30 19:15:00,473 - INFO - joeynmt.training - Epoch  46: total training loss 873.90
2021-09-30 19:15:00,473 - INFO - joeynmt.training - EPOCH 47
2021-09-30 19:15:20,032 - INFO - joeynmt.training - Epoch  47: total training loss 815.02
2021-09-30 19:15:20,033 - INFO - joeynmt.training - EPOCH 48
2021-09-30 19:15:39,651 - INFO - joeynmt.training - Epoch  48: total training loss 759.76
2021-09-30 19:15:39,651 - INFO - joeynmt.training - EPOCH 49
2021-09-30 19:15:59,137 - INFO - joeynmt.training - Epoch  49: total training loss 699.86
2021-09-30 19:15:59,138 - INFO - joeynmt.training - EPOCH 50
2021-09-30 19:16:18,895 - INFO - joeynmt.training - Epoch  50: total training loss 665.95
2021-09-30 19:16:18,895 - INFO - joeynmt.training - EPOCH 51
2021-09-30 19:16:38,442 - INFO - joeynmt.training - Epoch  51: total training loss 613.62
2021-09-30 19:16:38,442 - INFO - joeynmt.training - EPOCH 52
2021-09-30 19:16:58,189 - INFO - joeynmt.training - Epoch  52: total training loss 586.12
2021-09-30 19:16:58,190 - INFO - joeynmt.training - EPOCH 53
2021-09-30 19:17:17,881 - INFO - joeynmt.training - Epoch  53: total training loss 556.91
2021-09-30 19:17:17,881 - INFO - joeynmt.training - EPOCH 54
2021-09-30 19:17:37,535 - INFO - joeynmt.training - Epoch  54: total training loss 524.09
2021-09-30 19:17:37,536 - INFO - joeynmt.training - EPOCH 55
2021-09-30 19:17:57,403 - INFO - joeynmt.training - Epoch  55: total training loss 498.83
2021-09-30 19:17:57,404 - INFO - joeynmt.training - EPOCH 56
2021-09-30 19:18:17,165 - INFO - joeynmt.training - Epoch  56: total training loss 470.77
2021-09-30 19:18:17,166 - INFO - joeynmt.training - EPOCH 57
2021-09-30 19:18:37,060 - INFO - joeynmt.training - Epoch  57: total training loss 454.73
2021-09-30 19:18:37,060 - INFO - joeynmt.training - EPOCH 58
2021-09-30 19:18:39,840 - INFO - joeynmt.training - Epoch  58, Step:     4000, Batch Loss:     5.289903, Tokens per Sec:     5225, Lr: 0.500000
2021-09-30 19:18:56,747 - INFO - joeynmt.training - Epoch  58: total training loss 437.76
2021-09-30 19:18:56,747 - INFO - joeynmt.training - EPOCH 59
2021-09-30 19:19:16,552 - INFO - joeynmt.training - Epoch  59: total training loss 415.51
2021-09-30 19:19:16,553 - INFO - joeynmt.training - EPOCH 60
2021-09-30 19:19:36,187 - INFO - joeynmt.training - Epoch  60: total training loss 405.48
2021-09-30 19:19:36,188 - INFO - joeynmt.training - EPOCH 61
2021-09-30 19:19:55,786 - INFO - joeynmt.training - Epoch  61: total training loss 385.02
2021-09-30 19:19:55,786 - INFO - joeynmt.training - EPOCH 62
2021-09-30 19:20:15,519 - INFO - joeynmt.training - Epoch  62: total training loss 369.83
2021-09-30 19:20:15,520 - INFO - joeynmt.training - EPOCH 63
2021-09-30 19:20:35,227 - INFO - joeynmt.training - Epoch  63: total training loss 357.77
2021-09-30 19:20:35,227 - INFO - joeynmt.training - EPOCH 64
2021-09-30 19:20:54,879 - INFO - joeynmt.training - Epoch  64: total training loss 343.87
2021-09-30 19:20:54,879 - INFO - joeynmt.training - EPOCH 65
2021-09-30 19:21:14,642 - INFO - joeynmt.training - Epoch  65: total training loss 338.30
2021-09-30 19:21:14,642 - INFO - joeynmt.training - EPOCH 66
2021-09-30 19:21:34,355 - INFO - joeynmt.training - Epoch  66: total training loss 331.45
2021-09-30 19:21:34,356 - INFO - joeynmt.training - EPOCH 67
2021-09-30 19:21:54,172 - INFO - joeynmt.training - Epoch  67: total training loss 321.87
2021-09-30 19:21:54,173 - INFO - joeynmt.training - EPOCH 68
2021-09-30 19:22:13,946 - INFO - joeynmt.training - Epoch  68: total training loss 314.19
2021-09-30 19:22:13,946 - INFO - joeynmt.training - EPOCH 69
2021-09-30 19:22:33,634 - INFO - joeynmt.training - Epoch  69: total training loss 305.90
2021-09-30 19:22:33,634 - INFO - joeynmt.training - EPOCH 70
2021-09-30 19:22:53,425 - INFO - joeynmt.training - Epoch  70: total training loss 295.40
2021-09-30 19:22:53,425 - INFO - joeynmt.training - EPOCH 71
2021-09-30 19:23:13,160 - INFO - joeynmt.training - Epoch  71: total training loss 290.59
2021-09-30 19:23:13,161 - INFO - joeynmt.training - EPOCH 72
2021-09-30 19:23:21,702 - INFO - joeynmt.training - Epoch  72, Step:     5000, Batch Loss:     3.867747, Tokens per Sec:     5143, Lr: 0.500000
2021-09-30 19:23:32,881 - INFO - joeynmt.training - Epoch  72: total training loss 286.64
2021-09-30 19:23:32,881 - INFO - joeynmt.training - EPOCH 73
2021-09-30 19:23:52,657 - INFO - joeynmt.training - Epoch  73: total training loss 283.18
2021-09-30 19:23:52,657 - INFO - joeynmt.training - EPOCH 74
2021-09-30 19:24:12,711 - INFO - joeynmt.training - Epoch  74: total training loss 275.49
2021-09-30 19:24:12,712 - INFO - joeynmt.training - EPOCH 75
2021-09-30 19:24:32,618 - INFO - joeynmt.training - Epoch  75: total training loss 266.82
2021-09-30 19:24:32,618 - INFO - joeynmt.training - EPOCH 76
2021-09-30 19:24:52,471 - INFO - joeynmt.training - Epoch  76: total training loss 265.38
2021-09-30 19:24:52,471 - INFO - joeynmt.training - EPOCH 77
2021-09-30 19:25:12,361 - INFO - joeynmt.training - Epoch  77: total training loss 257.31
2021-09-30 19:25:12,362 - INFO - joeynmt.training - EPOCH 78
2021-09-30 19:25:32,016 - INFO - joeynmt.training - Epoch  78: total training loss 251.96
2021-09-30 19:25:32,017 - INFO - joeynmt.training - EPOCH 79
2021-09-30 19:25:51,797 - INFO - joeynmt.training - Epoch  79: total training loss 250.64
2021-09-30 19:25:51,798 - INFO - joeynmt.training - EPOCH 80
2021-09-30 19:26:11,370 - INFO - joeynmt.training - Epoch  80: total training loss 248.43
2021-09-30 19:26:11,371 - INFO - joeynmt.training - EPOCH 81
2021-09-30 19:26:31,295 - INFO - joeynmt.training - Epoch  81: total training loss 242.03
2021-09-30 19:26:31,295 - INFO - joeynmt.training - EPOCH 82
2021-09-30 19:26:51,084 - INFO - joeynmt.training - Epoch  82: total training loss 238.93
2021-09-30 19:26:51,084 - INFO - joeynmt.training - EPOCH 83
2021-09-30 19:27:10,688 - INFO - joeynmt.training - Epoch  83: total training loss 234.59
2021-09-30 19:27:10,689 - INFO - joeynmt.training - EPOCH 84
2021-09-30 19:27:30,419 - INFO - joeynmt.training - Epoch  84: total training loss 228.04
2021-09-30 19:27:30,419 - INFO - joeynmt.training - EPOCH 85
2021-09-30 19:27:50,138 - INFO - joeynmt.training - Epoch  85: total training loss 225.54
2021-09-30 19:27:50,139 - INFO - joeynmt.training - EPOCH 86
2021-09-30 19:28:04,308 - INFO - joeynmt.training - Epoch  86, Step:     6000, Batch Loss:     2.922307, Tokens per Sec:     5096, Lr: 0.500000
2021-09-30 19:28:09,879 - INFO - joeynmt.training - Epoch  86: total training loss 225.37
2021-09-30 19:28:09,879 - INFO - joeynmt.training - EPOCH 87
2021-09-30 19:28:29,674 - INFO - joeynmt.training - Epoch  87: total training loss 224.07
2021-09-30 19:28:29,674 - INFO - joeynmt.training - EPOCH 88
2021-09-30 19:28:49,423 - INFO - joeynmt.training - Epoch  88: total training loss 219.13
2021-09-30 19:28:49,423 - INFO - joeynmt.training - EPOCH 89
2021-09-30 19:29:09,312 - INFO - joeynmt.training - Epoch  89: total training loss 218.01
2021-09-30 19:29:09,312 - INFO - joeynmt.training - EPOCH 90
2021-09-30 19:29:29,049 - INFO - joeynmt.training - Epoch  90: total training loss 215.44
2021-09-30 19:29:29,050 - INFO - joeynmt.training - EPOCH 91
2021-09-30 19:29:48,845 - INFO - joeynmt.training - Epoch  91: total training loss 212.34
2021-09-30 19:29:48,845 - INFO - joeynmt.training - EPOCH 92
2021-09-30 19:30:08,556 - INFO - joeynmt.training - Epoch  92: total training loss 207.37
2021-09-30 19:30:08,556 - INFO - joeynmt.training - EPOCH 93
2021-09-30 19:30:28,220 - INFO - joeynmt.training - Epoch  93: total training loss 205.21
2021-09-30 19:30:28,221 - INFO - joeynmt.training - EPOCH 94
2021-09-30 19:30:48,042 - INFO - joeynmt.training - Epoch  94: total training loss 206.52
2021-09-30 19:30:48,042 - INFO - joeynmt.training - EPOCH 95
2021-09-30 19:31:07,812 - INFO - joeynmt.training - Epoch  95: total training loss 198.93
2021-09-30 19:31:07,813 - INFO - joeynmt.training - EPOCH 96
2021-09-30 19:31:27,381 - INFO - joeynmt.training - Epoch  96: total training loss 199.69
2021-09-30 19:31:27,382 - INFO - joeynmt.training - EPOCH 97
2021-09-30 19:31:47,362 - INFO - joeynmt.training - Epoch  97: total training loss 199.22
2021-09-30 19:31:47,363 - INFO - joeynmt.training - EPOCH 98
2021-09-30 19:32:07,051 - INFO - joeynmt.training - Epoch  98: total training loss 196.45
2021-09-30 19:32:07,052 - INFO - joeynmt.training - EPOCH 99
2021-09-30 19:32:26,705 - INFO - joeynmt.training - Epoch  99: total training loss 198.65
2021-09-30 19:32:26,706 - INFO - joeynmt.training - EPOCH 100
2021-09-30 19:32:46,302 - INFO - joeynmt.training - Epoch 100, Step:     7000, Batch Loss:     3.255667, Tokens per Sec:     5129, Lr: 0.500000
2021-09-30 19:32:46,303 - INFO - joeynmt.training - Epoch 100: total training loss 195.05
2021-09-30 19:32:46,303 - INFO - joeynmt.training - Training ended after 100 epochs.
2021-09-30 19:32:46,303 - INFO - joeynmt.training - Best validation result (greedy) at step        0:   -inf eval_metric.
2021-09-30 19:32:46,331 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 80
2021-09-30 19:32:46,331 - INFO - joeynmt.prediction - Loading model from models/BIG_model/0.ckpt
Traceback (most recent call last):
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/sw/arch/Debian10/EB_production/2019/software/Anaconda3/2018.12/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lcur0006/joeynmt/joeynmt/__main__.py", line 48, in <module>
    main()
  File "/home/lcur0006/joeynmt/joeynmt/__main__.py", line 35, in main
    train(cfg_file=args.config_path, skip_test=args.skip_test)
  File "/home/lcur0006/joeynmt/joeynmt/training.py", line 863, in train
    datasets=datasets_to_test)
  File "/home/lcur0006/joeynmt/joeynmt/prediction.py", line 321, in test
    model_checkpoint = load_checkpoint(ckpt, use_cuda=use_cuda)
  File "/home/lcur0006/joeynmt/joeynmt/helpers.py", line 284, in load_checkpoint
    assert os.path.isfile(path), "Checkpoint %s not found" % path
AssertionError: Checkpoint models/BIG_model/0.ckpt not found
srun: error: r31n4: task 0: Exited with exit code 1
