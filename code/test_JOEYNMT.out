2021-09-24 14:41:47,065 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-09-24 14:41:47,121 - INFO - joeynmt.data - Loading training data...
2021-09-24 14:41:53,916 - INFO - joeynmt.data - Building vocabulary...
2021-09-24 14:47:45,046 - INFO - joeynmt.data - Loading dev data...
2021-09-24 14:47:45,151 - INFO - joeynmt.data - Loading test data...
2021-09-24 14:47:45,258 - INFO - joeynmt.data - Data loaded.
2021-09-24 14:47:45,258 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-09-24 14:47:45,990 - INFO - joeynmt.model - Enc-dec model built.
2021-09-24 14:47:46,000 - INFO - joeynmt.training - Total params: 31435200
2021-09-24 14:47:50,185 - INFO - joeynmt.helpers - cfg.name                           : BIG_model
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.src                       : en
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.trg                       : fr
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.train                     : test/data/test_data/train
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.dev                       : test/data/test_data/val
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.test                      : test/data/test_data/test
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 50
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.src_voc_min_freq          : 0
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.src_voc_limit             : 100000
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.trg_voc_min_freq          : 0
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.data.trg_voc_limit             : 100000
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-09-24 14:47:50,186 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 5e-07
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.clip_grad_norm        : 1.0
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.batch_size            : 80
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.patience              : 10
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.5
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.epochs                : 20
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 7362
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 1000
2021-09-24 14:47:50,187 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/BIG_model
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2]
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.rnn_type         : lstm
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 100
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : False
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 100
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.bidirectional    : True
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.2
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 1
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.decoder.rnn_type         : lstm
2021-09-24 14:47:50,188 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 100
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : False
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.emb_scale        : False
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 200
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.2
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_dropout   : 0.2
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 1
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.input_feeding    : True
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.init_hidden      : bridge
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - cfg.model.decoder.attention        : bahdanau
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - Data set sizes: 
	train 237322,
	valid 6050,
	test 7214
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - First training example:
	[SRC] en
	[TRG] fr
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) the (6) ." (7) . (8) to (9) of
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) _ (5) , (6) de (7) . (8) NULL (9) ."
2021-09-24 14:47:50,189 - INFO - joeynmt.helpers - Number of Src words (types): 71685
2021-09-24 14:47:50,190 - INFO - joeynmt.helpers - Number of Trg words (types): 78343
2021-09-24 14:47:50,190 - INFO - joeynmt.training - Model(
	encoder=RecurrentEncoder(LSTM(100, 100, batch_first=True, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(300, 200, batch_first=True), attention=BahdanauAttention),
	src_embed=Embeddings(embedding_dim=100, vocab_size=71685),
	trg_embed=Embeddings(embedding_dim=100, vocab_size=78343))
2021-09-24 14:47:50,314 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 80
	total batch size (w. parallel & accumulation): 80
2021-09-24 14:47:50,314 - INFO - joeynmt.training - EPOCH 1
2021-09-24 14:50:54,613 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:    97.625175, Tokens per Sec:     8011, Lr: 0.000300
2021-09-24 14:53:57,830 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:    88.176796, Tokens per Sec:     8075, Lr: 0.000300
2021-09-24 14:56:52,723 - INFO - joeynmt.training - Epoch   1: total training loss 293329.92
2021-09-24 14:56:52,724 - INFO - joeynmt.training - EPOCH 2
2021-09-24 14:56:59,075 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:    77.392586, Tokens per Sec:     7741, Lr: 0.000300
2021-09-24 14:59:59,940 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:    68.850082, Tokens per Sec:     8178, Lr: 0.000300
2021-09-24 15:03:01,388 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:    78.395531, Tokens per Sec:     8155, Lr: 0.000300
2021-09-24 15:05:51,007 - INFO - joeynmt.training - Epoch   2: total training loss 244077.37
2021-09-24 15:05:51,008 - INFO - joeynmt.training - EPOCH 3
2021-09-24 15:06:03,312 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:    83.712975, Tokens per Sec:     7907, Lr: 0.000300
2021-09-24 15:09:03,849 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:    77.050514, Tokens per Sec:     8216, Lr: 0.000300
2021-09-24 15:10:30,831 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 15:10:30,832 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 15:10:30,832 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 15:10:30,875 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 15:10:32,054 - INFO - joeynmt.training - Example #0
2021-09-24 15:10:32,055 - INFO - joeynmt.training - 	Source:     en
2021-09-24 15:10:32,055 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 15:10:32,055 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 15:10:32,055 - INFO - joeynmt.training - Example #1
2021-09-24 15:10:32,055 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 15:10:32,056 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 15:10:32,056 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _ _ _ NULL _ _
2021-09-24 15:10:32,056 - INFO - joeynmt.training - Example #2
2021-09-24 15:10:32,056 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 15:10:32,056 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 15:10:32,056 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _ _ _ NULL _ _
2021-09-24 15:10:32,057 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     7362: bleu:   7.83, loss: 502415.5938, ppl:  61.3777, duration: 22.8471s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 15:12:29,204 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:    71.234703, Tokens per Sec:     8071, Lr: 0.000300
2021-09-24 15:15:12,359 - INFO - joeynmt.training - Epoch   3: total training loss 225467.86
2021-09-24 15:15:12,360 - INFO - joeynmt.training - EPOCH 4
2021-09-24 15:15:30,505 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:    76.217766, Tokens per Sec:     8060, Lr: 0.000300
2021-09-24 15:18:31,091 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:    74.349358, Tokens per Sec:     8209, Lr: 0.000300
2021-09-24 15:21:30,602 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:    73.169098, Tokens per Sec:     8234, Lr: 0.000300
2021-09-24 15:24:06,878 - INFO - joeynmt.training - Epoch   4: total training loss 213662.56
2021-09-24 15:24:06,878 - INFO - joeynmt.training - EPOCH 5
2021-09-24 15:24:30,831 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:    83.008354, Tokens per Sec:     8115, Lr: 0.000300
2021-09-24 15:27:30,365 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:    73.339798, Tokens per Sec:     8236, Lr: 0.000300
2021-09-24 15:30:29,870 - INFO - joeynmt.training - Epoch   5, Step:    14000, Batch Loss:    78.778564, Tokens per Sec:     8238, Lr: 0.000300
2021-09-24 15:33:01,802 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 15:33:01,803 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 15:33:01,803 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 15:33:01,846 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 15:33:03,158 - INFO - joeynmt.training - Example #0
2021-09-24 15:33:03,158 - INFO - joeynmt.training - 	Source:     en
2021-09-24 15:33:03,159 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 15:33:03,159 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 15:33:03,159 - INFO - joeynmt.training - Example #1
2021-09-24 15:33:03,159 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 15:33:03,159 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 15:33:03,159 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; ai commencé à mon point , j&apos; ai commencé à ma vie à ma vie ."
2021-09-24 15:33:03,160 - INFO - joeynmt.training - Example #2
2021-09-24 15:33:03,160 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 15:33:03,160 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 15:33:03,160 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _ _ _ NULL _ _
2021-09-24 15:33:03,160 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    14724: bleu:  10.02, loss: 452648.8750, ppl:  40.8225, duration: 23.0893s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 15:33:24,845 - INFO - joeynmt.training - Epoch   5: total training loss 203876.12
2021-09-24 15:33:24,846 - INFO - joeynmt.training - EPOCH 6
2021-09-24 15:33:54,858 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:    62.742950, Tokens per Sec:     8086, Lr: 0.000300
2021-09-24 15:36:55,343 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:    58.445019, Tokens per Sec:     8201, Lr: 0.000300
2021-09-24 15:39:55,380 - INFO - joeynmt.training - Epoch   6, Step:    17000, Batch Loss:    66.897034, Tokens per Sec:     8229, Lr: 0.000300
2021-09-24 15:42:19,297 - INFO - joeynmt.training - Epoch   6: total training loss 190372.74
2021-09-24 15:42:19,298 - INFO - joeynmt.training - EPOCH 7
2021-09-24 15:42:55,640 - INFO - joeynmt.training - Epoch   7, Step:    18000, Batch Loss:    55.579235, Tokens per Sec:     8086, Lr: 0.000300
2021-09-24 15:45:55,191 - INFO - joeynmt.training - Epoch   7, Step:    19000, Batch Loss:    58.572956, Tokens per Sec:     8218, Lr: 0.000300
2021-09-24 15:48:55,753 - INFO - joeynmt.training - Epoch   7, Step:    20000, Batch Loss:    66.890106, Tokens per Sec:     8187, Lr: 0.000300
2021-09-24 15:51:13,861 - INFO - joeynmt.training - Epoch   7: total training loss 172828.46
2021-09-24 15:51:13,862 - INFO - joeynmt.training - EPOCH 8
2021-09-24 15:51:55,954 - INFO - joeynmt.training - Epoch   8, Step:    21000, Batch Loss:    59.345387, Tokens per Sec:     8082, Lr: 0.000300
2021-09-24 15:54:55,718 - INFO - joeynmt.training - Epoch   8, Step:    22000, Batch Loss:    51.899391, Tokens per Sec:     8216, Lr: 0.000300
2021-09-24 15:55:33,724 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 15:55:33,724 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 15:55:33,724 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 15:55:33,769 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 15:55:34,969 - INFO - joeynmt.training - Example #0
2021-09-24 15:55:34,969 - INFO - joeynmt.training - 	Source:     en
2021-09-24 15:55:34,969 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 15:55:34,969 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 15:55:34,970 - INFO - joeynmt.training - Example #1
2021-09-24 15:55:34,970 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 15:55:34,970 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 15:55:34,970 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais jeune , je me souviens de me rappeler un matin pour le faire de mon téléphone ."
2021-09-24 15:55:34,970 - INFO - joeynmt.training - Example #2
2021-09-24 15:55:34,971 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 15:55:34,971 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 15:55:34,971 - INFO - joeynmt.training - 	Hypothesis: Mon père était de l&apos; école de la mort de son petit peu , en prison ."
2021-09-24 15:55:34,971 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    22086: bleu:  13.49, loss: 373977.5625, ppl:  21.4251, duration: 23.7753s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 15:58:21,908 - INFO - joeynmt.training - Epoch   8, Step:    23000, Batch Loss:    59.686123, Tokens per Sec:     8141, Lr: 0.000300
2021-09-24 16:00:34,526 - INFO - joeynmt.training - Epoch   8: total training loss 158256.33
2021-09-24 16:00:34,527 - INFO - joeynmt.training - EPOCH 9
2021-09-24 16:01:22,438 - INFO - joeynmt.training - Epoch   9, Step:    24000, Batch Loss:    51.193737, Tokens per Sec:     8137, Lr: 0.000300
2021-09-24 16:04:23,124 - INFO - joeynmt.training - Epoch   9, Step:    25000, Batch Loss:    47.513428, Tokens per Sec:     8204, Lr: 0.000300
2021-09-24 16:07:23,127 - INFO - joeynmt.training - Epoch   9, Step:    26000, Batch Loss:    48.165180, Tokens per Sec:     8220, Lr: 0.000300
2021-09-24 16:09:29,626 - INFO - joeynmt.training - Epoch   9: total training loss 147091.57
2021-09-24 16:09:29,627 - INFO - joeynmt.training - EPOCH 10
2021-09-24 16:10:23,667 - INFO - joeynmt.training - Epoch  10, Step:    27000, Batch Loss:    42.569054, Tokens per Sec:     8151, Lr: 0.000300
2021-09-24 16:13:23,609 - INFO - joeynmt.training - Epoch  10, Step:    28000, Batch Loss:    45.649654, Tokens per Sec:     8233, Lr: 0.000300
2021-09-24 16:16:23,719 - INFO - joeynmt.training - Epoch  10, Step:    29000, Batch Loss:    51.826454, Tokens per Sec:     8206, Lr: 0.000300
2021-09-24 16:18:06,105 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 16:18:06,106 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 16:18:06,106 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 16:18:06,149 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 16:18:07,326 - INFO - joeynmt.training - Example #0
2021-09-24 16:18:07,326 - INFO - joeynmt.training - 	Source:     en
2021-09-24 16:18:07,326 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 16:18:07,326 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 16:18:07,327 - INFO - joeynmt.training - Example #1
2021-09-24 16:18:07,327 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 16:18:07,327 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 16:18:07,327 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais 11 ans , je me souviens de me rappeler un matin pour la douleur de ma maison ."
2021-09-24 16:18:07,327 - INFO - joeynmt.training - Example #2
2021-09-24 16:18:07,328 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 16:18:07,328 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 16:18:07,328 - INFO - joeynmt.training - 	Hypothesis: "Mon père a été de l&apos; enfant de la BBC sur son petit bout , et la radio ."
2021-09-24 16:18:07,328 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    29448: bleu:  17.22, loss: 332164.1562, ppl:  15.2095, duration: 22.4440s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 16:18:49,552 - INFO - joeynmt.training - Epoch  10: total training loss 138180.84
2021-09-24 16:18:49,553 - INFO - joeynmt.training - EPOCH 11
2021-09-24 16:19:49,874 - INFO - joeynmt.training - Epoch  11, Step:    30000, Batch Loss:    45.185722, Tokens per Sec:     8129, Lr: 0.000300
2021-09-24 16:22:49,465 - INFO - joeynmt.training - Epoch  11, Step:    31000, Batch Loss:    43.974010, Tokens per Sec:     8232, Lr: 0.000300
2021-09-24 16:25:49,763 - INFO - joeynmt.training - Epoch  11, Step:    32000, Batch Loss:    47.549740, Tokens per Sec:     8189, Lr: 0.000300
2021-09-24 16:27:45,187 - INFO - joeynmt.training - Epoch  11: total training loss 131006.80
2021-09-24 16:27:45,188 - INFO - joeynmt.training - EPOCH 12
2021-09-24 16:28:51,276 - INFO - joeynmt.training - Epoch  12, Step:    33000, Batch Loss:    43.033566, Tokens per Sec:     8155, Lr: 0.000300
2021-09-24 16:31:51,965 - INFO - joeynmt.training - Epoch  12, Step:    34000, Batch Loss:    45.761585, Tokens per Sec:     8192, Lr: 0.000300
2021-09-24 16:34:52,854 - INFO - joeynmt.training - Epoch  12, Step:    35000, Batch Loss:    42.548412, Tokens per Sec:     8176, Lr: 0.000300
2021-09-24 16:36:41,613 - INFO - joeynmt.training - Epoch  12: total training loss 125004.14
2021-09-24 16:36:41,614 - INFO - joeynmt.training - EPOCH 13
2021-09-24 16:37:53,308 - INFO - joeynmt.training - Epoch  13, Step:    36000, Batch Loss:    41.715282, Tokens per Sec:     8122, Lr: 0.000300
2021-09-24 16:40:39,806 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 16:40:39,807 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 16:40:39,807 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 16:40:39,850 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 16:40:41,004 - INFO - joeynmt.training - Example #0
2021-09-24 16:40:41,005 - INFO - joeynmt.training - 	Source:     en
2021-09-24 16:40:41,005 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 16:40:41,005 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 16:40:41,005 - INFO - joeynmt.training - Example #1
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais 11 ans , je me souviens de me rappeler un matin pour le son de la joie dans ma maison ."
2021-09-24 16:40:41,006 - INFO - joeynmt.training - Example #2
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 16:40:41,006 - INFO - joeynmt.training - 	Hypothesis: Mon père a été écouter de la BBC sur sa petite fille .
2021-09-24 16:40:41,007 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    36810: bleu:  19.90, loss: 310674.9375, ppl:  12.7538, duration: 21.7548s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 16:41:17,194 - INFO - joeynmt.training - Epoch  13, Step:    37000, Batch Loss:    40.714348, Tokens per Sec:     8142, Lr: 0.000300
2021-09-24 16:44:17,383 - INFO - joeynmt.training - Epoch  13, Step:    38000, Batch Loss:    47.002831, Tokens per Sec:     8183, Lr: 0.000300
2021-09-24 16:46:00,650 - INFO - joeynmt.training - Epoch  13: total training loss 119969.27
2021-09-24 16:46:00,651 - INFO - joeynmt.training - EPOCH 14
2021-09-24 16:47:18,257 - INFO - joeynmt.training - Epoch  14, Step:    39000, Batch Loss:    42.235424, Tokens per Sec:     8181, Lr: 0.000300
2021-09-24 16:50:19,505 - INFO - joeynmt.training - Epoch  14, Step:    40000, Batch Loss:    32.226665, Tokens per Sec:     8154, Lr: 0.000300
2021-09-24 16:53:19,744 - INFO - joeynmt.training - Epoch  14, Step:    41000, Batch Loss:    36.535370, Tokens per Sec:     8213, Lr: 0.000300
2021-09-24 16:54:56,842 - INFO - joeynmt.training - Epoch  14: total training loss 115638.41
2021-09-24 16:54:56,843 - INFO - joeynmt.training - EPOCH 15
2021-09-24 16:56:20,852 - INFO - joeynmt.training - Epoch  15, Step:    42000, Batch Loss:    36.268158, Tokens per Sec:     8108, Lr: 0.000300
2021-09-24 16:59:21,467 - INFO - joeynmt.training - Epoch  15, Step:    43000, Batch Loss:    38.202145, Tokens per Sec:     8182, Lr: 0.000300
2021-09-24 17:02:22,429 - INFO - joeynmt.training - Epoch  15, Step:    44000, Batch Loss:    38.843948, Tokens per Sec:     8176, Lr: 0.000300
2021-09-24 17:03:13,182 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 17:03:13,182 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 17:03:13,182 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 17:03:13,226 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 17:03:14,420 - INFO - joeynmt.helpers - delete models/BIG_model/7362.ckpt
2021-09-24 17:03:14,519 - INFO - joeynmt.training - Example #0
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Source:     en
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 17:03:14,519 - INFO - joeynmt.training - Example #1
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 17:03:14,519 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais 11 ans , je me souviens de me réveiller un matin pour le son de la joie dans ma maison ."
2021-09-24 17:03:14,519 - INFO - joeynmt.training - Example #2
2021-09-24 17:03:14,520 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 17:03:14,520 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 17:03:14,520 - INFO - joeynmt.training - 	Hypothesis: "Mon père a été écouter à la BBC de la BBC sur sa petite radio , la radio ."
2021-09-24 17:03:14,520 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    44172: bleu:  22.28, loss: 298354.3438, ppl:  11.5290, duration: 21.3402s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 17:04:16,440 - INFO - joeynmt.training - Epoch  15: total training loss 111805.72
2021-09-24 17:04:16,441 - INFO - joeynmt.training - EPOCH 16
2021-09-24 17:05:46,779 - INFO - joeynmt.training - Epoch  16, Step:    45000, Batch Loss:    35.933270, Tokens per Sec:     8137, Lr: 0.000300
2021-09-24 17:08:47,368 - INFO - joeynmt.training - Epoch  16, Step:    46000, Batch Loss:    33.647335, Tokens per Sec:     8194, Lr: 0.000300
2021-09-24 17:11:47,498 - INFO - joeynmt.training - Epoch  16, Step:    47000, Batch Loss:    29.138651, Tokens per Sec:     8204, Lr: 0.000300
2021-09-24 17:13:12,758 - INFO - joeynmt.training - Epoch  16: total training loss 108402.79
2021-09-24 17:13:12,759 - INFO - joeynmt.training - EPOCH 17
2021-09-24 17:14:48,506 - INFO - joeynmt.training - Epoch  17, Step:    48000, Batch Loss:    38.518456, Tokens per Sec:     8163, Lr: 0.000300
2021-09-24 17:17:49,498 - INFO - joeynmt.training - Epoch  17, Step:    49000, Batch Loss:    35.982162, Tokens per Sec:     8179, Lr: 0.000300
2021-09-24 17:20:49,472 - INFO - joeynmt.training - Epoch  17, Step:    50000, Batch Loss:    36.459457, Tokens per Sec:     8194, Lr: 0.000300
2021-09-24 17:22:09,044 - INFO - joeynmt.training - Epoch  17: total training loss 105417.58
2021-09-24 17:22:09,045 - INFO - joeynmt.training - EPOCH 18
2021-09-24 17:23:50,700 - INFO - joeynmt.training - Epoch  18, Step:    51000, Batch Loss:    39.249065, Tokens per Sec:     8157, Lr: 0.000300
2021-09-24 17:25:47,816 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 17:25:47,817 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 17:25:47,817 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 17:25:47,862 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 17:25:49,154 - INFO - joeynmt.helpers - delete models/BIG_model/14724.ckpt
2021-09-24 17:25:49,255 - INFO - joeynmt.training - Example #0
2021-09-24 17:25:49,255 - INFO - joeynmt.training - 	Source:     en
2021-09-24 17:25:49,255 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 17:25:49,255 - INFO - joeynmt.training - 	Hypothesis: _ _ NULL _ _
2021-09-24 17:25:49,255 - INFO - joeynmt.training - Example #1
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais 11 , je me souviens de m&apos; arrêter un matin à la joie dans ma maison ."
2021-09-24 17:25:49,256 - INFO - joeynmt.training - Example #2
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 17:25:49,256 - INFO - joeynmt.training - 	Hypothesis: "Mon père m&apos; a écouté à la BBC sur la BBC , la radio gris ."
2021-09-24 17:25:49,256 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    51534: bleu:  23.18, loss: 290280.6562, ppl:  10.7909, duration: 22.3831s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 17:27:15,222 - INFO - joeynmt.training - Epoch  18, Step:    52000, Batch Loss:    32.470535, Tokens per Sec:     8132, Lr: 0.000300
2021-09-24 17:30:15,355 - INFO - joeynmt.training - Epoch  18, Step:    53000, Batch Loss:    41.459026, Tokens per Sec:     8203, Lr: 0.000300
2021-09-24 17:31:28,714 - INFO - joeynmt.training - Epoch  18: total training loss 102768.03
2021-09-24 17:31:28,715 - INFO - joeynmt.training - EPOCH 19
2021-09-24 17:33:16,631 - INFO - joeynmt.training - Epoch  19, Step:    54000, Batch Loss:    32.228848, Tokens per Sec:     8145, Lr: 0.000300
2021-09-24 17:36:16,733 - INFO - joeynmt.training - Epoch  19, Step:    55000, Batch Loss:    30.974302, Tokens per Sec:     8211, Lr: 0.000300
2021-09-24 17:39:17,729 - INFO - joeynmt.training - Epoch  19, Step:    56000, Batch Loss:    33.991283, Tokens per Sec:     8188, Lr: 0.000300
2021-09-24 17:40:24,899 - INFO - joeynmt.training - Epoch  19: total training loss 100384.27
2021-09-24 17:40:24,900 - INFO - joeynmt.training - EPOCH 20
2021-09-24 17:42:18,659 - INFO - joeynmt.training - Epoch  20, Step:    57000, Batch Loss:    34.720974, Tokens per Sec:     8124, Lr: 0.000300
2021-09-24 17:45:19,496 - INFO - joeynmt.training - Epoch  20, Step:    58000, Batch Loss:    31.915241, Tokens per Sec:     8212, Lr: 0.000300
2021-09-24 17:48:20,739 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 17:48:20,739 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 17:48:20,739 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 17:48:20,784 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-09-24 17:48:21,855 - INFO - joeynmt.helpers - delete models/BIG_model/22086.ckpt
2021-09-24 17:48:21,952 - INFO - joeynmt.training - Example #0
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Source:     en
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Reference:  fr
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Hypothesis: fr
2021-09-24 17:48:21,952 - INFO - joeynmt.training - Example #1
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Source:     "When I was 11 , I remember waking up one morning to the sound of joy in my house ."
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Reference:  "J&apos; avais 11 ans , je me souviens qu&apos; un matin j&apos; ai été réveillée par des cris de joie dans toute la maison ."
2021-09-24 17:48:21,952 - INFO - joeynmt.training - 	Hypothesis: "Quand j&apos; étais 11 ans , je me souviens de réveiller un matin pour le son de la joie dans ma maison ."
2021-09-24 17:48:21,952 - INFO - joeynmt.training - Example #2
2021-09-24 17:48:21,953 - INFO - joeynmt.training - 	Source:     "My father was listening to BBC News on his small , gray radio ."
2021-09-24 17:48:21,953 - INFO - joeynmt.training - 	Reference:  Mon père était en train d&apos; écouter le journal de la BBC sur sa petite radio grise .
2021-09-24 17:48:21,953 - INFO - joeynmt.training - 	Hypothesis: "Mon père m&apos; a écouté de la BBC sur sa petite fille , radio gris ."
2021-09-24 17:48:21,953 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    58896: bleu:  24.68, loss: 288769.4688, ppl:  10.6581, duration: 20.7490s
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
/home/lcur0008/joeynmt/joeynmt/plotting.py:57: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(column_labels, minor=False, rotation="vertical")
/home/lcur0008/joeynmt/joeynmt/plotting.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(row_labels, minor=False)
2021-09-24 17:48:42,443 - INFO - joeynmt.training - Epoch  20, Step:    59000, Batch Loss:    38.067600, Tokens per Sec:     8093, Lr: 0.000300
2021-09-24 17:49:44,226 - INFO - joeynmt.training - Epoch  20: total training loss 98222.52
2021-09-24 17:49:44,227 - INFO - joeynmt.training - Training ended after  20 epochs.
2021-09-24 17:49:44,227 - INFO - joeynmt.training - Best validation result (greedy) at step    58896:  24.68 eval_metric.
2021-09-24 17:49:44,252 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 80
2021-09-24 17:49:44,252 - INFO - joeynmt.prediction - Loading model from models/BIG_model/58896.ckpt
2021-09-24 17:49:44,512 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-09-24 17:49:45,204 - INFO - joeynmt.model - Enc-dec model built.
2021-09-24 17:49:45,272 - INFO - joeynmt.prediction - Decoding on dev set (test/data/test_data/val.fr)...
2021-09-24 17:51:17,965 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 17:51:17,965 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 17:51:17,965 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 17:51:18,009 - INFO - joeynmt.prediction -  dev bleu[13a]:   8.31 [Beam search decoding with beam size = 5 and alpha = 1.0]
2021-09-24 17:51:18,014 - INFO - joeynmt.prediction - Translations saved to: models/BIG_model/00058896.hyps.dev
2021-09-24 17:51:18,015 - INFO - joeynmt.prediction - Decoding on test set (test/data/test_data/test.fr)...
2021-09-24 17:53:10,836 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-09-24 17:53:10,837 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-09-24 17:53:10,837 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-09-24 17:53:10,887 - INFO - joeynmt.prediction - test bleu[13a]:  10.19 [Beam search decoding with beam size = 5 and alpha = 1.0]
2021-09-24 17:53:10,893 - INFO - joeynmt.prediction - Translations saved to: models/BIG_model/00058896.hyps.test
